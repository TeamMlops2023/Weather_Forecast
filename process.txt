Etape 0.1 : création de la branche de travail (C'est comme si je réalisé une feature)

Les commandes :
	- Création de la branche : 
        => git branch proto-eric
    - On se positionne sur la branche :
        => git checkout proto-eric
    - Modification du fichier README.md pour fair un premier commit pour push la branche
        => (on modifie le fichier)
        => git add README.md
        => git status
        => git commit -m "Test 0 README pour new branch proto-eric"
        => git status
        => git push
        => On vérifie sur github l'ajout de la branche

Etape 0.2 : Modification de l'organisation des dossiers et du fichier README
        => On fait tout ce qu'il y a à faire sur le terminal sans faire de commande git
        => git status
        => On add et commit un par un les modifs pour associé à chaque commit une action (plus simple par la suite d'annuler une action isolé)
            => git add nom-fichier-concerné-un-par-un
            => git commit -m "Expliqué l'action add juste au-dessus"
        => git push

==================================================================================================================================================
Ci-dessous on liste les étapes plus générique d'un projet
==================================================================================================================================================
Etape 1 : Ajout des data
    => Création d'un dossier data
    => Ajout d'un fichier csv (par exemple)

Etape 2 : Ajout du modèle avec son commande
    => Création d'un dossier notebook
    => Ajout du code du modèle
    => Ajout du modèle entrainer

Etape 3.1 : Ajout du bloc code fastapi
    => Création d'un dossier src
    => Création d'un fichier app.py contenant le code qui définit la features fastapi
    => Création d'un fichier start_server.py qui sera l'exécutable pour lancer l'instance fastapi

    Remarques :
        Pour tester le code fastapi on peut créer un environnement de travail temporairement 
        sur lequel on va installé les packages nécessaires et où on va éxécuter le code directement via une commande.

        Pour la création d'un environnement :
            - Création de l'environnement : 
                => python3 -m venv env_name
            - Activation de l'environnement :
                => source env_name/bin/activate
            - Désactivation de l'environnement (à la fin) :
                => deactivate
            Lien pour le cours sur environnement :https://openclassrooms.com/fr/courses/6951236-mettez-en-place-votre-environnement-python/7014018-creez-votre-premier-environnement-virtuel

        Pour éxécuter le code fastapi :
            - On import les packages nécessaire dont :
                => pip install --no-cache-dir -r requirements.txt
            - Exécution du code app.py directement :
                => uvicorn app:app --reload  (app:app => nom du fichier:nom de l'élément fastapi créé)
            - On peut ensuite développer et tester le code
            - Une fois terminé on récupère les packages dans un fichier requirements.txt et on sort de l'environnement temporaire que l'on supprime pour ne pas le monter sur github
            - Pour récuperer les packages :
                => pip3 freeze > requirements.txt
            - Pour sortir de l'environnement temporaire :
                => deactivate
            - Pour supprimer l'environnement temporaire :
                => rm -r env


            PS : 
            - j'ai créer deux fichiers setup qui rassemble les requêtes (avant test fastapi et après pour nettoyage) => setup_test_fastapi.sh et setup_clean_fastapi.sh
                    => source setup_test_fastapi.sh
                    => source setup_clean_fastapi.sh
            - En ce qui concerne le dossier __pycache__ à voir ce qu'il faut faire ... Pour l'instant je supprime
            - Pour le fichier modele_logs.log il faut déterminer la démarche pour l'instant je supprime avant le lancement de l'api

    => On peut boucler sur l'étape précédente en sauvegardant régulièrement sur git jusqu'à satisfaction

    => Pour anticiper la partie indus des bloc test on va créer un fichier commande_test_fastapi.txt et rédiger les tests à faire via des commande CURL

Etape 3.X : Création de différents bloc en suivant ce principe selon le besoin
    => ...

Etape 4.1 : Containerisation Docker
    On va créer les différentes images et tester l'ensemble avec un docker-compose
    
    => Pour chaque bloc qui nécessite que l'on créer notre propre image on va créer un dossier image_bloc_name
        => Dans ce dossier on ajoute un fichier Dockerfile
        => On developpe le code du Dockerfile
        => Une fois terminé on va le tester, pour cela :
            => On créer l'image : docker image build . -t my_image_name:latest
            => On définie les différents ressources nécessaires commes les autres containers, les networks, les volumes, les variables d'environnement, etc.
            => On créer un container : docker container run --rm --network my_network_test --name bloc_name my_image_name (à adapter)
            => On applique les test définis en amont
            => Un fois validé on arrête le tout
        
            Remarques : 
            On peut s'implifier ce process et le rendre plus progressif en travaillant directement avec un docker-compose.
            On créer un fichier compose qu'on aliment bloc par bloc au fur et à mesure que les tests sont concluent.
            Par exemple si je veux un bloc fastapi avec un bloc test automatisé je vais d'abords implémenter le bloc fastapi, le tester puis ajouter le bloc test_auto et retester.
            C'est plus pratique si on a plusieurs bloc.
            Dans tous les cas le docker-compose permet de faciliter l'automatisation des test d'intégration.

    => Pour faciliter cette partie je conseil l'utilisation de fichier setup.sh/setup_remove.sh qui permettent de lancer plusieurs commande d'un coup.
        Cela fait gagné beaucoup de temps et évite l'erreur humaine.

Etape 4.2 : Envoie à docker hub
    Comme son nom l'indique l'idée ici est de mettre en place un fichier setup.sh qui défini les commandes pour envoyer une image sur le hub.
    Voici un exemple :
        docker image build . -t my_image:latest

        docker tag my_image laceric/datascientest_exam_kubernetest_fastapi

        docker push laceric/datascientest_exam_kubernetest_fastapi

        docker rmi laceric/datascientest_exam_kubernetest_fastapi

        docker image rm my_image

Etape 5 : Création d'un Jenkinsfile pour automatiser le contrôle lors de push sur github et de merge avec une branche supérieur
    L'idée est de mettre en place un serveur jenkins que l'on activera dans un premier temps uniquement pour tester l'automatisation avant chaque push important.
    On définira un webhook qui se basera sur un évènement pour éxécuter un fichier jenkinsfile.
    Dans ce fichier Jenkinsfile on intègrera un ensemble de commande pour vérifier que le code monté est valide (test) et par la suite il devra push les modifications sur le serveur kubernetes.

    Remarque : Une VM peut abriter Jenkins et Kubernetes et tout le reste est réalisé en local sur les vm perso (gain de place)

Etape 6 : Mise en place de kubernetes
    On va créer un dossier kubernetes dans lequel on mettra l'ensemble des fichiers déclaratives.yml nécessaires au serveur kubernetes.
    On testera en local à petite échelle (genre 1 pod).
    Puis si validé on push pour qu'il soit gérer par jenkins.
